# Compaction Strategy
- Log file names will have a common prefix, followed by the datetime utc (in the format `%Y%m%d%H%M%S`) they were created, followed by a common suffix.
- In-memory index will be a table from `keys` to `index: {file_name, offset}`.
- The index will always be built at startup (KvStore::open).
- There will be two constants to trigger the compaction algorithm: `CMD_KEY_FACTOR` and `CMDS_THRESHOLD`.
- To be able to know when to trigger compaction using the constants, KvStore will have to keep a counter of the total number of cmds written on all log files.
- Compaction will be triggered when: `total_number_of_commands` > `CMDS_THRESHOLD` && `total_number_of_commands` / `total_number_of_keys_in_memory` > `CMD_KEY_FACTOR`.
- There will be another constant to trigger the creation of a new log file: `OFFSET_CURR_FILE_THRESHOLD`.
- To be able to know when to trigger the creation of a new log file, KvStore will have to keep a counter of the total number of cmds written on the current log file.
- The creation of a new log file will be triggered when: `curr_file_next_cmd_offset` > `CURR_FILE_OFFSET_THRESHOLD`.
- After writting a command to the log file, the algorithm will check the predicate for compaction to be triggered and deal with it. Then it will check for the predicate for the creation of a new log file and deal with that.
- The compaction strategy will be:
  - List all the `file_name`s that match the log file name format in the log directory.
  - Turn the list of `file_name`s to a list of structures of the form `file_keys: {file_name, cmd_counter, keys}` where the initial value for all `keys`s will be vec![].
  - For each entry in the in-memory index that has a matching `file_name` with the `file_keys.file_name` push that `key` into `file_keys.keys`.
  - Sort all `file_keys` by the `cmd_counter / file_keys.keys.len()` in the descending order.
  - While the predicate for triggering compaction holds:
    - Pop the first `file_keys`.
    - Open the `file_keys.file_name` in read mode.
    - For each `key` in `file_keys.keys`:
      - Read the `value` of the `key` using first the in-memory index to find the offset and then the read from file at the offset.
      - Write the command to the current log file.
      - Update the entry in the in-memory index.
      - Check the predicate for the creation of a new log file and deal with that. (This can be optimized later)
    - Close and delete the file with name: `file_keys.file_name`.
